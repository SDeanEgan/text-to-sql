{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21hGe7Mr0gos",
    "outputId": "314c5079-a527-458c-fb20-f274ec69bb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 10 15:42:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 59%   45C    P8             23W /  350W |     964MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3052    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3064    C+G   ...a\\Local\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      3624    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      6856    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10804    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     17924    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18292    C+G   ...a\\Local\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     21708    C+G   ...h2txyewy\\InputApp\\TextInputHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True if GPU is available\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IADibkaEs79C"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "login(token=\"\") # place your own token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XBTV-c1nFiAX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codet5 = 'Salesforce/codet5-base' #changed to use CodeT5-base!\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(codet5)\n",
    "model = T5ForConditionalGeneration.from_pretrained(codet5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "name = 'codet5-base-sql-create-context'\n",
    "path = 'finetuned/codet5-base-sql-create-context'\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hM3s5q981Ga6",
    "outputId": "1299c801-ba7f-46ba-a422-e052272ed9bc"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({ 'train': load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]'),\n",
    "                            'validation': load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]'),\n",
    "                      })\n",
    "\n",
    "def format_dataset(example):\n",
    "    return {'input': 'schema: \\n' + example['context'][:420] + '\\n\\ntranslate to SQL: ' + example['question'], 'target': example['answer']}\n",
    "\n",
    "formatted_dataset = dataset.map(format_dataset, remove_columns=dataset['train'].column_names).shuffle(seed=42) # also shuffles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b8roCmG1tTA",
    "outputId": "005aae69-e4bb-4e43-e59d-48e42200b60e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'target'],\n",
       "        num_rows: 62862\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input', 'target'],\n",
       "        num_rows: 7857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5V6i4yG2omO",
    "outputId": "90297a95-3942-4d14-d201-75105a41ae3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'schema: \\nCREATE TABLE table_name_42 (decision VARCHAR, series VARCHAR)\\n\\ntranslate to SQL: Which Decision has a Series of 3 – 3?',\n",
       " 'target': 'SELECT decision FROM table_name_42 WHERE series = \"3 – 3\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ppkB_UwQH7a6"
   },
   "outputs": [],
   "source": [
    "# map with tokenizer to provide tokenized dataset to the Seq2SeqTrainer\n",
    "def tokenize_function(example_batch):\n",
    "    '''use direct tokenizer call, construct encodings dictionary'''\n",
    "    input_encodings = tokenizer(example_batch['input'], padding='max_length', truncation=True, max_length=256)\n",
    "    target_encodings = tokenizer(example_batch['target'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "\n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids'],\n",
    "        'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "    return encodings\n",
    "\n",
    "tokenized_dataset = formatted_dataset.map(tokenize_function, batched=True, remove_columns=formatted_dataset['train'].column_names)\n",
    "\n",
    "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "tokenized_dataset.set_format(type='torch', columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZH-HHDI0IWrX"
   },
   "outputs": [],
   "source": [
    "# arguments for Seq2SeqTrainer\n",
    "trainer_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=path,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    "    #fp16=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SqWbevh5Kelo"
   },
   "outputs": [],
   "source": [
    "# Metric calculation \n",
    "# Exact Match https://huggingface.co/spaces/evaluate-metric/exact_match\n",
    "# ROUGE2 score https://huggingface.co/spaces/evaluate-metric/rouge\n",
    "# BLEU score https://huggingface.co/spaces/evaluate-metric/sacrebleu\n",
    "exact_match = evaluate.load(\"exact_match\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # Decode the predictions and labels\n",
    "    pred_ids[pred_ids == -100] = tokenizer.pad_token_id\n",
    "    \n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return {\n",
    "        \"exact_match\": exact_match.compute(predictions=pred_str, references=label_str)['exact_match'],\n",
    "        \"rouge2\": rouge.compute(predictions=pred_str, references=label_str)[\"rouge2\"],\n",
    "        \"bleu\": sacrebleu.compute(predictions=pred_str, references=label_str)[\"score\"],\n",
    "    }\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=trainer_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "c-MSUMJqKrqb",
    "outputId": "3cf2a23e-af5b-45c1-9f74-8b8814dd13b7"
   },
   "outputs": [],
   "source": [
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qZR_ASsEK5Lp",
    "outputId": "7d3b37cc-29a5-4bfe-ee49-38bdad08f864"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39290' max='39290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39290/39290 3:37:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.880801</td>\n",
       "      <td>75.189148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.239277</td>\n",
       "      <td>0.882050</td>\n",
       "      <td>75.406126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.244750</td>\n",
       "      <td>0.883199</td>\n",
       "      <td>75.586255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.883711</td>\n",
       "      <td>75.712976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.245132</td>\n",
       "      <td>0.883943</td>\n",
       "      <td>75.678024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39290, training_loss=0.0044258481440091445, metrics={'train_runtime': 13060.1177, 'train_samples_per_second': 24.066, 'train_steps_per_second': 3.008, 'total_flos': 9.57007772909568e+16, 'train_loss': 0.0044258481440091445, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4f_eBTCeTHA",
    "outputId": "6c0ea618-bb69-43b2-a999-24f0f941b30e"
   },
   "outputs": [],
   "source": [
    "# store the model and maybe push to huggingface hub?\n",
    "trainer.save_model()\n",
    "\n",
    "tokenizer.save_pretrained(path)\n",
    "\n",
    "trainer.create_model_card()\n",
    "\n",
    "#trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V7bmzeQgqtA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKESPh7i0YCiRexy88VPG1",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "T5-wikiSQL-with-HF-transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (project_env)",
   "language": "python",
   "name": "project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03772b2541dd43c5a614829c7155cdc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49e47d1b79cf46a3881843ff210016bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2d910b8525c40879a4a31d805e384ab",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72ce6fb8cb244ced88abc340f5bf1258",
      "value": 1
     }
    },
    "72ce6fb8cb244ced88abc340f5bf1258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a378b1afb7a407f93dacd7b6f10a7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96f366309e644e0cbe7411f4c49f2c10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d910b8525c40879a4a31d805e384ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a821ed3f960d44b99aefa77814fa23f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb4cf1ebfc514891a253d9cd6a874ffc",
      "placeholder": "​",
      "style": "IPY_MODEL_03772b2541dd43c5a614829c7155cdc3",
      "value": "100%"
     }
    },
    "c740bd8b679448d9ae4badc67c36400f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96f366309e644e0cbe7411f4c49f2c10",
      "placeholder": "​",
      "style": "IPY_MODEL_8a378b1afb7a407f93dacd7b6f10a7a7",
      "value": " 1/1 [00:00&lt;00:00, 11.34ba/s]"
     }
    },
    "cb4cf1ebfc514891a253d9cd6a874ffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7ec75bd9d14f4caa3ce9f87ff7bfbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dab3b41563e2413493b796a22776a6d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a821ed3f960d44b99aefa77814fa23f1",
       "IPY_MODEL_49e47d1b79cf46a3881843ff210016bb",
       "IPY_MODEL_c740bd8b679448d9ae4badc67c36400f"
      ],
      "layout": "IPY_MODEL_cc7ec75bd9d14f4caa3ce9f87ff7bfbb"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
