{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc3073b-9595-457c-ab6a-5bd43d5c7ced",
   "metadata": {},
   "source": [
    "# Text-to-SQL Assistance With Claude and CodeT5\n",
    "\n",
    "This notebook serves as a proof of concept to use a private LLM API and a finetuned transformer model in conjunction to answer questions about databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8ef724-efef-4389-86b3-2d4aa27aa2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include your anthropic api key\n",
    "anthropic_api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e713ecfc-be3a-4bcb-89fd-a27f22e0b816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z370-I\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import anthropic\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# set up the anthropic api client\n",
    "CLIENT = anthropic.Anthropic(\n",
    "    api_key=anthropic_api_key,  # Your Anthropic API key\n",
    "    \n",
    "    # Optional \n",
    "    base_url=\"https://api.anthropic.com\",  # Default API endpoint\n",
    "    timeout=60,  # Request timeout in seconds\n",
    "    max_retries=2,  # Number of times to retry failed requests\n",
    "    default_headers=None,  # Additional headers to include in requests\n",
    ")\n",
    "CLAUDE = \"claude-3-7-sonnet-20250219\"\n",
    "\n",
    "PATH = 'finetuned/codet5-base-wikisql'\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(PATH)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bc11b-7764-4aa0-bd68-ca53b81efa07",
   "metadata": {},
   "source": [
    "## Query a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d40dcc-4fa6-48c7-9bb1-c9223ba040a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to interact with anthropic api\n",
    "def ask_claude(question, schema):\n",
    "    prompt = f\"\"\"Here is the schema for a database:\n",
    "{schema}\n",
    "Given this schema, can you output a SQL query to answer the following question? \n",
    "Only output the SQL query, use double quotes instead of single quotes in the query, and no markdown formatting or newline characters.\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = CLIENT.messages.create(\n",
    "            model=CLAUDE,\n",
    "            max_tokens=512,\n",
    "            messages=[{\n",
    "                \"role\": 'user', \"content\":  prompt\n",
    "            }]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error querying API: {e}\"\n",
    "\n",
    "# function to generate from finetuned CodeT5-base\n",
    "def ask_codet5(question, schema):\n",
    "    prompt = 'schema: \\n' + str(schema)[:420] + '\\n\\ntranslate to SQL: ' + str(question)\n",
    "    inputs = tokenizer(prompt, truncation=True, padding='max_length', max_length=256, return_tensors='pt').to(device)\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=256)[0]\n",
    "    prediction = tokenizer.decode(output, skip_special_tokens=True)\n",
    "            \n",
    "    return prediction\n",
    "    \n",
    "# prompt database with query\n",
    "def execute_query(path, query):\n",
    "    \"\"\" execute an SQL query given a path to sqlite db\"\"\"\n",
    "    conn = sqlite3.connect(path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"PRAGMA case_sensitive_like = OFF;\") # case requirements are annoying\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()[:]\n",
    "    except sqlite3.Error as e:\n",
    "        result = f\"SQL Error: {e}\"\n",
    "    \n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "def get_table_schema(path, table):\n",
    "    conn = sqlite3.connect(path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:    \n",
    "        schema = cursor.execute(f\"PRAGMA table_info({table})\").fetchall()\n",
    "        result = f\"CREATE TABLE {table} (\\n\" + \"\\n\".join([f\"{col[1]} {col[2]}\" for col in schema]) + \"\\n)\"\n",
    "    except sqlite3.Error as e:\n",
    "        result = f\"SQL Error: {e}\"\n",
    "    \n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "def get_database_schema(path):\n",
    "    conn = sqlite3.connect(path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n",
    "        result = cursor.fetchall()\n",
    "    except sqlite3.Error as e:\n",
    "        result = f\"SQL Error: {e}\"\n",
    "\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "# acquire a table's schema, prompt model, execute selection\n",
    "def ask(question, table, db_path):\n",
    "    table_schema = get_table_schema(db_path, table)\n",
    "    \n",
    "    codet5_prediction = ask_codet5(question, table_schema)\n",
    "    claude_prediction = ask_claude(question, table_schema)\n",
    "    \n",
    "    print(question)\n",
    "    print(f'Schema: \\n{table_schema}\\n')\n",
    "    print(f'CodeT5 says: \\n{codet5_prediction}')\n",
    "    print(f'Claude says: \\n{claude_prediction}')\n",
    "    print('/////////////////////////////////////////////\\n')\n",
    "\n",
    "    print(\"Pick a number: \\n1) Try what CodeT5 said.\\n2) Use Claude's answer.\\n3) I'll give my own SQL query!\")\n",
    "    selection = input()\n",
    "    while selection not in ['1','2','3']:\n",
    "        selection = input(\"I didn't catch that.\\nPlease try again: \")\n",
    "\n",
    "    if selection == '1':\n",
    "        choice = codet5_prediction\n",
    "    elif selection == '2':\n",
    "        choice = claude_prediction\n",
    "    else: \n",
    "        choice = input(\"Okay, let's have your query: \\n\")\n",
    "    \n",
    "    return execute_query(db_path, choice)\n",
    "\n",
    "def run():\n",
    "    # example natural language question\n",
    "    question = \"What is the average UnitPrice in invoice_items?\"\n",
    "    table = \"invoice_items\"\n",
    "    \n",
    "    db_path = 'sqlite/chinook.db'\n",
    "\n",
    "    result = ask(question, table, db_path)\n",
    "\n",
    "    print(f\"Here's what we got back:\\n{result[:500]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab49b25-8140-49bf-95ad-a5460616f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the average UnitPrice in invoice_items?\n",
      "Schema: \n",
      "CREATE TABLE invoice_items (\n",
      "InvoiceLineId INTEGER\n",
      "InvoiceId INTEGER\n",
      "TrackId INTEGER\n",
      "UnitPrice NUMERIC(10,2)\n",
      "Quantity INTEGER\n",
      ")\n",
      "\n",
      "CodeT5 says: \n",
      "SELECT AVG UnitPrice in invoice_items FROM table WHERE IDATAInvoiceLineId =\n",
      "InvoiceId AND IDATAInvoiceTrackId =\n",
      "InvoiceId AND IDATAQuantity =\n",
      "\n",
      "Claude says: \n",
      "SELECT AVG(UnitPrice) FROM invoice_items\n",
      "/////////////////////////////////////////////\n",
      "\n",
      "Pick a number: \n",
      "1) Try what CodeT5 said.\n",
      "2) Use Claude's answer.\n",
      "3) I'll give my own SQL query!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what we got back:\n",
      "[(1.0395535714285522,)]...\n"
     ]
    }
   ],
   "source": [
    "#run the thing\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f676ec-6e93-4662-9b0a-c1d09d136636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
